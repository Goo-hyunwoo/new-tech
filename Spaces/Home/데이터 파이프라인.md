# 데이터 파이프라인

> 참고자료: https://tech.socarcorp.kr/data/2023/01/17/build-fms-data-pipeline-1.html
> 쏘카의 데이터 파이프라인 구축기 1편

데이터 파이프라인이란, 운영되는 시스템의 비정형 데이터들을 모으는 시스템
쏘카에서는 운영 중인 차들이 실시간으로 보내오는 데이터들을 집계하는 시스템 생성


# 아키텍처

### 1. 스트리밍 파이프라인
> 운영 중인 Device -> IoT Core(MQTT) -> MSK(메시지 브로커) -> Kafka Consumer / Connect
> Kafka Consumer -> Redis (실시간 조회용 DB)
> Kafka Connect -> S3(클라우드 스토리지), DB(NoSQL)

위의 구조로 실시간으로 전송되는 각지의 로그 데이터 등 비정형 데이터가 클라우드에 적재
다양한 데이터를 Queue 구조로 보관(IoT Core)
Queue의 데이터를 적절한 로직과 연결(MSK)
데이터 레이크의 역할을 수행
모니터링에 필요한 집계 정보 수집

### 2. 배치 파이프라인
> S3 -> AWS Lamda -> (AWS Glue Data Catalog) -> AWS Redshift -> Airflow -> RDBMS

Glue Data Catalog: 비정형/반정형 데이터들을 SQL형태로 다룰 수 있도록 저장하는 메타 스토어
스키마 추론(저장), 외부 테이블 형태로 데이터 추론(RDB 추론)

Airflow: AirBnB에서 개발한 Work flow 관리 오픈소스 배치 처리 라이브러리

### 3. 데이터 흐름
> 1. 차량에서 다양한 데이터 수집
> 2. 수집된 데이터 발송 주기에 맞춰 IoT Core로 전송
> 3. 메시지 브로커에 저장된 메시지 Kafka Topic으로 라우팅
> 4. Kafka Topic의 각 파티션 메시지는 데이터 싱크(S3)로 적재(Json), Redis용은 Consumer로 적재
> 5. Json 객체는 Lamda를 통해 분류/변형되어 S3에 재적재(Redshift/Athena Format)
> 6. Airflow로 스케줄링된 Redshift 쿼리를 통해 데이터를 집계하여 RDBMS(Data Mart)에 저장


### Apache Kafka
> https://sjh9708.tistory.com/151#google_vignette

> 데이터의 실시간 스트리밍 및 이벤트 처리를 위한 오픈소스
> 대규모 분산 시스템에서 안정적이고 확장 가능한 메시지 큐와 이벤트 스트리밍 플랫폼으로 사용
> 데이터의 실시간 처리 및 분석에 사용

특징
> 1. Event-Oriented: 이벤트 스트리밍 플랫폼으로서, 이벤트 중심 처리
> 2. Publish-Subscribe: 이벤트 발생(Producer) -> Kafka Topic(Consumer의 관심사) -> Consumer
> 3. 분산 아키텍처: 여러 브로커 노드로 이루어진 분산 시스템
> 4. 확장성(Scale-out): 클러스터를 여러 대의 서버로 확장 가능, 수천 대의 브로커와 수십만 개의 Partition으로 이루어진 대규모 클러스터 구성 가능

구성요소
![[Pasted image 20240513164317.png]]

